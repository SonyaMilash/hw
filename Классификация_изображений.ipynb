{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b063209-5c5a-4039-91a2-845a6c2759a3",
      "metadata": {
        "id": "7b063209-5c5a-4039-91a2-845a6c2759a3"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle torch torchvision torchmetrics ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223a8969-cb32-46b1-8fe4-db2be18b05ed",
      "metadata": {
        "id": "223a8969-cb32-46b1-8fe4-db2be18b05ed"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from copy import deepcopy\n",
        "# from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchmetrics import Accuracy\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2fc778-6609-46b1-b533-5c336b8a2946",
      "metadata": {
        "id": "df2fc778-6609-46b1-b533-5c336b8a2946"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a3eee8-0611-4f9d-bf2b-bdb70751c553",
      "metadata": {
        "id": "d9a3eee8-0611-4f9d-bf2b-bdb70751c553"
      },
      "source": [
        "Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b3541b-8aae-477e-a893-f7a1da646590",
      "metadata": {
        "id": "a4b3541b-8aae-477e-a893-f7a1da646590"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = './'\n",
        "SPLIT_DATA_DIR = ROOT_DIR + 'data/'\n",
        "\n",
        "TRAIN_DATA_DIR = SPLIT_DATA_DIR + 'train/'\n",
        "VALID_DATA_DIR = SPLIT_DATA_DIR + 'valid/'\n",
        "TEST_DATA_DIR = SPLIT_DATA_DIR + 'test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c864e8-60ab-4824-854d-d3624926dd2a",
      "metadata": {
        "id": "e0c864e8-60ab-4824-854d-d3624926dd2a"
      },
      "outputs": [],
      "source": [
        "def train_valid_split(\n",
        "    num_val_images_per_class,\n",
        "    num_test_images_per_class\n",
        "):\n",
        "\n",
        "    os.makedirs(VALID_DATA_DIR, exist_ok = True)\n",
        "\n",
        "    classes = os.listdir(TRAIN_DATA_DIR)\n",
        "\n",
        "    for class_name in classes:\n",
        "\n",
        "        list_of_pics = os.listdir(TRAIN_DATA_DIR + class_name)\n",
        "\n",
        "        os.mkdir(VALID_DATA_DIR + class_name)\n",
        "\n",
        "        val_list_of_pics = np.random.choice(list_of_pics, size = num_val_images_per_class, replace=False)\n",
        "\n",
        "        for pic in val_list_of_pics:\n",
        "            shutil.move(TRAIN_DATA_DIR + class_name + '/' + pic, VALID_DATA_DIR + class_name + '/' + pic)\n",
        "\n",
        "    os.makedirs(TEST_DATA_DIR, exist_ok = True)\n",
        "\n",
        "    for class_name in classes:\n",
        "\n",
        "        list_of_pics = os.listdir(TRAIN_DATA_DIR + class_name)\n",
        "\n",
        "        os.mkdir(TEST_DATA_DIR + class_name)\n",
        "\n",
        "        val_list_of_pics = np.random.choice(list_of_pics, size = num_val_images_per_class, replace=False)\n",
        "\n",
        "        for pic in val_list_of_pics:\n",
        "            shutil.move(TRAIN_DATA_DIR + class_name + '/' + pic, TEST_DATA_DIR + class_name + '/' + pic)\n",
        "\n",
        "if not os.path.isdir(VALID_DATA_DIR):\n",
        "    train_valid_split(100, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd200b3-c3cb-4b49-9522-5a41a7f6de52",
      "metadata": {
        "id": "4cd200b3-c3cb-4b49-9522-5a41a7f6de52"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "BATCH_SIZE = 64\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomHorizontalFlip(p=0.5)\n",
        "])\n",
        "\n",
        "transform_valid = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(TRAIN_DATA_DIR, transform=transform_train)\n",
        "valid_dataset = datasets.ImageFolder(VALID_DATA_DIR, transform=transform_valid)\n",
        "test_dataset = datasets.ImageFolder(TEST_DATA_DIR, transform = transform_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "valid_dataloader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Автоэнкодер**"
      ],
      "metadata": {
        "id": "FsLHpzjlcLvR"
      },
      "id": "FsLHpzjlcLvR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fde543c-203d-40ea-84fe-718e1cc3b535",
      "metadata": {
        "id": "1fde543c-203d-40ea-84fe-718e1cc3b535"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        def initialization(layer):\n",
        "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.ConvTranspose2d):\n",
        "                nn.init.kaiming_normal_(layer.weight)\n",
        "                layer.bias.data.fill_(0.)\n",
        "\n",
        "        self.encoder = nn.Sequential(nn.Conv2d(3, 128, kernel_size=(3, 3), padding = 1, stride = 1),\n",
        "                                     nn.ELU(),\n",
        "                                     nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "                                     nn.Conv2d(128, 64, kernel_size=(3, 3), padding = 1, stride = 1),\n",
        "                                     nn.ELU(),\n",
        "                                     nn.MaxPool2d(kernel_size=(2, 2)),\n",
        "                                     nn.Conv2d(64, 32, kernel_size=(3, 3), padding = 1, stride = 1),\n",
        "                                     nn.ELU()\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(nn.ConvTranspose2d(32, 64, kernel_size=(3, 3),\n",
        "                                                        padding = 1, stride = 1),\n",
        "                                     nn.ELU(),\n",
        "                                     nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                     nn.ConvTranspose2d(64, 128, kernel_size=(3, 3),\n",
        "                                                        padding = 1, stride = 1),\n",
        "                                     nn.ELU(),\n",
        "                                     nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                     nn.ConvTranspose2d(128, 3, kernel_size=(3, 3),\n",
        "                                                        padding = 1, stride = 1),\n",
        "                                     nn.ELU()\n",
        "        )\n",
        "\n",
        "        self.apply(initialization)\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_code = self.encoder(x)\n",
        "        reconstruction = self.decoder(latent_code)\n",
        "        return reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5759de81-5173-496e-a862-3df17d585384",
      "metadata": {
        "id": "5759de81-5173-496e-a862-3df17d585384"
      },
      "outputs": [],
      "source": [
        "for x_train, y_train in  train_dataloader:\n",
        "    break\n",
        "\n",
        "for x_valid, y_valid in  valid_dataloader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fad08c9-4ab2-4b96-a2b4-4cfbb5061b24",
      "metadata": {
        "id": "6fad08c9-4ab2-4b96-a2b4-4cfbb5061b24"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder()\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0003)\n",
        "\n",
        "def run_train(model, criterion, optimizer, x_train, x_valid):\n",
        "    for epoch in range(50):\n",
        "        print(f'epoch: {epoch}')\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_train)\n",
        "        loss = criterion(output, x_train)\n",
        "        loss.backward()\n",
        "        print(f'loss_train: {loss.item()}')\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        output = model(x_valid)\n",
        "        loss = criterion(output, x_valid)\n",
        "        print(f'loss_valid: {loss.item()}')\n",
        "\n",
        "run_train(model, criterion, optimizer, x_train, x_valid) # переобучение на одном батче\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb971a3-df53-429b-a60e-c4b514d1e04d",
      "metadata": {
        "id": "9eb971a3-df53-429b-a60e-c4b514d1e04d"
      },
      "outputs": [],
      "source": [
        "class FullModel(nn.Module):\n",
        "    def __init__(self,ae_model, num_classes: int = 200) -> None:\n",
        "        super(FullModel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            ae_model.encoder\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d((3, 3))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(32 * 5 * 5, 2024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2024, 2024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2024, num_classes),\n",
        "        )\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95ac9034-84d3-4d68-a42c-de3a8f068b8f",
      "metadata": {
        "id": "95ac9034-84d3-4d68-a42c-de3a8f068b8f"
      },
      "outputs": [],
      "source": [
        "class model_training():\n",
        "\n",
        "    def __init__(self, lr, train_autoencode, trainloader, testloader, device, model):\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.device = device\n",
        "        self.train_autoencode = train_autoencode\n",
        "\n",
        "        self.model = model\n",
        "        if train_autoencode:\n",
        "            self.loss_fn = torch.nn.MSELoss()\n",
        "        else:\n",
        "            self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "        self.opt = optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr = lr,\n",
        "            weight_decay = 0.0001\n",
        "        )\n",
        "\n",
        "        self.best_model = None\n",
        "        self.best_epoch = None\n",
        "\n",
        "        self.loss_train = []\n",
        "        self.loss_test = []\n",
        "        self.metric_train = []\n",
        "        self.metric_test = []\n",
        "\n",
        "    def accuracy(self, y_predicts, y_labels):\n",
        "        acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
        "        return acc\n",
        "\n",
        "    def train_nn(self, trainloader, model, opt, loss_fn, device):\n",
        "\n",
        "        model.train()\n",
        "        running_loss_train = []\n",
        "        running_acc_train = []\n",
        "        if self.train_autoencode:\n",
        "            for batch in tqdm(train_dataloader):\n",
        "                inputs, labels = batch\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                outputs = model(inputs).to(device)\n",
        "\n",
        "\n",
        "                loss = loss_fn(outputs, inputs)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "                running_loss_train.append(loss.item())\n",
        "                running_acc_train.append(loss.item())\n",
        "        else:\n",
        "            for batch in tqdm(train_dataloader):\n",
        "                inputs, labels = batch\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                outputs = model(inputs).to(device)\n",
        "                y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
        "\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "                running_loss_train.append(loss.item())\n",
        "                running_acc_train.append(self.accuracy(y_pred, labels))\n",
        "\n",
        "\n",
        "        return model, running_loss_train, running_acc_train\n",
        "\n",
        "    def eval_nn(self, testloader, model, loss_fn, device):\n",
        "\n",
        "        model.eval()\n",
        "        running_loss_test = []\n",
        "        running_acc_test = []\n",
        "        if self.train_autoencode:\n",
        "            for batch in tqdm(valid_dataloader):\n",
        "                inputs, labels = batch\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                outputs = model(inputs).to(device)\n",
        "                loss = loss_fn(outputs, inputs)\n",
        "\n",
        "                running_loss_test.append(loss.item())\n",
        "                running_acc_test.append(loss.item())\n",
        "        else:\n",
        "\n",
        "\n",
        "            for batch in tqdm(valid_dataloader):\n",
        "\n",
        "                inputs, labels = batch\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs).to(device)\n",
        "                y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "\n",
        "                running_loss_test.append(loss.item())\n",
        "                running_acc_test.append(self.accuracy(y_pred, labels))\n",
        "\n",
        "        return running_loss_test, running_acc_test\n",
        "\n",
        "    def training_loop(self, max_epochs = 10):\n",
        "\n",
        "        print('Начинаю обучение')\n",
        "        start_training_time = time.time()\n",
        "\n",
        "        for epoch in tqdm(range(max_epochs)):\n",
        "\n",
        "            start_epoch_time = time.time()\n",
        "\n",
        "            self.model, running_loss_train, running_acc_train = self.train_nn(\n",
        "                self.trainloader,\n",
        "                self.model,\n",
        "                self.opt,\n",
        "                self.loss_fn,\n",
        "                self.device\n",
        "            )\n",
        "\n",
        "            running_loss_test, running_acc_test = self.eval_nn(\n",
        "                self.testloader,\n",
        "                self.model,\n",
        "                self.loss_fn,\n",
        "                self.device\n",
        "            )\n",
        "\n",
        "            self.loss_train.append(np.mean(running_loss_train))\n",
        "            self.loss_test.append(np.mean(running_loss_test))\n",
        "\n",
        "            self.metric_train.append(np.mean(running_acc_train))\n",
        "            self.metric_test.append(np.mean(running_acc_test))\n",
        "\n",
        "            if np.mean(running_acc_test) >= np.max(self.metric_test):\n",
        "                self.best_model = deepcopy(self.model)\n",
        "                self.best_epoch = epoch\n",
        "                torch.save(main_loop.best_model, './models/custom_model.pt')\n",
        "\n",
        "            duration_epoch = time.time() - start_epoch_time\n",
        "\n",
        "            print(f\"\"\"EPOCH {epoch} :\n",
        "            train_loss: {self.loss_train[-1]:.5f}\n",
        "            test_loss: {self.loss_test[-1]:.5f}\n",
        "            train_acc: {self.metric_train[-1]:.5f}\n",
        "            test_acc: {self.metric_test[-1]:.5f}\n",
        "            Эпоха заняла по времени {round(duration_epoch / 60, 2)} минут\"\"\")\n",
        "\n",
        "        duration_total = time.time() - start_training_time\n",
        "        print(f'Всего обучение заняло: {round(duration_total / 60, 2)} минут')\n",
        "        print(f'Лучшее значение метрики было достингнуто на {self.best_epoch} эпохе')\n",
        "\n",
        "        fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(10, 8))\n",
        "\n",
        "        axes[0, 0].plot(range(max_epochs), self.loss_train)\n",
        "        axes[0, 0].set_title('loss_train')\n",
        "\n",
        "        axes[0, 1].plot(range(max_epochs), self.loss_test)\n",
        "        axes[0, 1].set_title('loss_test')\n",
        "\n",
        "        axes[1, 0].plot(range(max_epochs), self.metric_train)\n",
        "        axes[1, 0].set_title('metric_train')\n",
        "\n",
        "        axes[1, 1].plot(range(max_epochs), self.metric_test)\n",
        "        axes[1, 1].set_title('metric_test')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a314b2b4-ed8c-4abf-820c-342ee76fd298",
      "metadata": {
        "scrolled": true,
        "id": "a314b2b4-ed8c-4abf-820c-342ee76fd298"
      },
      "outputs": [],
      "source": [
        "model_ae = AutoEncoder()\n",
        "model_ae.to(DEVICE)\n",
        "train_autoencode = True\n",
        "\n",
        "main_loop_ae = model_training(0.01,train_autoencode, train_dataloader, valid_dataloader, DEVICE, model_ae)\n",
        "main_loop_ae.training_loop(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c72267c-8a6d-4025-90b4-21e96df7698e",
      "metadata": {
        "id": "6c72267c-8a6d-4025-90b4-21e96df7698e"
      },
      "outputs": [],
      "source": [
        "model = FullModel(model_ae)\n",
        "model.features.requires_grad_ = False\n",
        "model.to(DEVICE)\n",
        "train_autoencode = False\n",
        "main_loop = model_training(0.01, train_autoencode,\n",
        "                           train_dataloader,\n",
        "                           valid_dataloader,\n",
        "                           DEVICE, model)\n",
        "main_loop.training_loop(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a79895a-6987-45fe-9f56-02499bbff178",
      "metadata": {
        "id": "6a79895a-6987-45fe-9f56-02499bbff178"
      },
      "outputs": [],
      "source": [
        "best_model = torch.load('./models/custom_model.pt')\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(y_predicts, y_labels):\n",
        "    acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
        "    return acc\n",
        "\n",
        "best_model.eval()\n",
        "running_loss_test = []\n",
        "running_acc_test = []\n",
        "\n",
        "for batch in tqdm(valid_dataloader):\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = best_model(inputs).to(DEVICE)\n",
        "    y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(DEVICE)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    running_loss_test.append(loss.item())\n",
        "    running_acc_test.append(accuracy(y_pred, labels))\n",
        "\n",
        "\n",
        "print(np.mean(running_loss_test))\n",
        "print(np.mean(running_acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**"
      ],
      "metadata": {
        "id": "4hozCGfacZdB"
      },
      "id": "4hozCGfacZdB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67814cf-c963-472b-92cd-3c8698e2dfe8",
      "metadata": {
        "scrolled": true,
        "id": "c67814cf-c963-472b-92cd-3c8698e2dfe8"
      },
      "outputs": [],
      "source": [
        "resnet18 = models.resnet18(pretrained=True)\n",
        "print(resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532e4fb4-4730-4d19-b9df-3426a4f4e107",
      "metadata": {
        "id": "532e4fb4-4730-4d19-b9df-3426a4f4e107"
      },
      "outputs": [],
      "source": [
        "class Pretrainde_RESNET18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        pretrained_net = models.resnet18(pretrained=True)\n",
        "\n",
        "        self.features = torch.nn.Sequential(*(list(pretrained_net.children())[:-1]))\n",
        "\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=300),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=300, out_features=200)\n",
        "        )\n",
        "        nn.init.kaiming_normal_(self.classifier[0].weight)\n",
        "        nn.init.kaiming_normal_(self.classifier[2].weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = nn.Flatten(start_dim = 1)(features)\n",
        "        logits = self.classifier(features)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f7d13c-ff34-4dc6-9578-f2a2fb5aecab",
      "metadata": {
        "id": "38f7d13c-ff34-4dc6-9578-f2a2fb5aecab"
      },
      "outputs": [],
      "source": [
        "class model_training():\n",
        "\n",
        "    def __init__(self, lr, trainloader, testloader, device, model):\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.device = device\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.opt = optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr = lr,\n",
        "            weight_decay = 0.0001\n",
        "        )\n",
        "\n",
        "        self.best_model = None\n",
        "        self.best_epoch = None\n",
        "\n",
        "        self.loss_train = []\n",
        "        self.loss_test = []\n",
        "        self.metric_train = []\n",
        "        self.metric_test = []\n",
        "\n",
        "    def accuracy(self, y_predicts, y_labels):\n",
        "        acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
        "        return acc\n",
        "\n",
        "    def train_nn(self, trainloader, model, opt, loss_fn, device):\n",
        "\n",
        "        model.train()\n",
        "        running_loss_train = []\n",
        "        running_acc_train = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            outputs = model(inputs).to(device)\n",
        "            y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running_loss_train.append(loss.item())\n",
        "            running_acc_train.append(self.accuracy(y_pred, labels))\n",
        "\n",
        "        return model, running_loss_train, running_acc_train\n",
        "\n",
        "    def eval_nn(self, testloader, model, loss_fn, device):\n",
        "\n",
        "        model.eval()\n",
        "        running_loss_test = []\n",
        "        running_acc_test = []\n",
        "\n",
        "        for batch in tqdm(valid_dataloader):\n",
        "\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs).to(device)\n",
        "            y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            running_loss_test.append(loss.item())\n",
        "            running_acc_test.append(self.accuracy(y_pred, labels))\n",
        "\n",
        "        return running_loss_test, running_acc_test\n",
        "\n",
        "    def training_loop(self, max_epochs = 10):\n",
        "\n",
        "        print('Начинаю обучение')\n",
        "        start_training_time = time.time()\n",
        "\n",
        "        for epoch in tqdm(range(max_epochs)):\n",
        "\n",
        "            start_epoch_time = time.time()\n",
        "\n",
        "            self.model, running_loss_train, running_acc_train = self.train_nn(\n",
        "                self.trainloader,\n",
        "                self.model,\n",
        "                self.opt,\n",
        "                self.loss_fn,\n",
        "                self.device\n",
        "            )\n",
        "\n",
        "            running_loss_test, running_acc_test = self.eval_nn(\n",
        "                self.testloader,\n",
        "                self.model,\n",
        "                self.loss_fn,\n",
        "                self.device\n",
        "            )\n",
        "\n",
        "            self.loss_train.append(np.mean(running_loss_train))\n",
        "            self.loss_test.append(np.mean(running_loss_test))\n",
        "\n",
        "            self.metric_train.append(np.mean(running_acc_train))\n",
        "            self.metric_test.append(np.mean(running_acc_test))\n",
        "\n",
        "            if np.mean(running_acc_test) >= np.max(self.metric_test):\n",
        "                self.best_model = deepcopy(self.model)\n",
        "                self.best_epoch = epoch\n",
        "                torch.save(main_loop.best_model, './models/custom_transfer_model.pt')\n",
        "\n",
        "            duration_epoch = time.time() - start_epoch_time\n",
        "\n",
        "            print(f\"\"\"EPOCH {epoch} :\n",
        "            train_loss: {self.loss_train[-1]:.5f}\n",
        "            test_loss: {self.loss_test[-1]:.5f}\n",
        "            train_acc: {self.metric_train[-1]:.5f}\n",
        "            test_acc: {self.metric_test[-1]:.5f}\n",
        "            Эпоха заняла по времени {round(duration_epoch / 60, 2)} минут\"\"\")\n",
        "\n",
        "        duration_total = time.time() - start_training_time\n",
        "        print(f'Всего обучение заняло: {round(duration_total / 60, 2)} минут')\n",
        "        print(f'Лучшее значение метрики было достингнуто на {self.best_epoch} эпохе')\n",
        "\n",
        "        fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(10, 8))\n",
        "\n",
        "        axes[0, 0].plot(range(max_epochs), self.loss_train)\n",
        "        axes[0, 0].set_title('loss_train')\n",
        "\n",
        "        axes[0, 1].plot(range(max_epochs), self.loss_test)\n",
        "        axes[0, 1].set_title('loss_test')\n",
        "\n",
        "        axes[1, 0].plot(range(max_epochs), self.metric_train)\n",
        "        axes[1, 0].set_title('metric_train')\n",
        "\n",
        "        axes[1, 1].plot(range(max_epochs), self.metric_test)\n",
        "        axes[1, 1].set_title('metric_test')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b35d5b34-8ff5-494c-ba18-879ea68fb925",
      "metadata": {
        "id": "b35d5b34-8ff5-494c-ba18-879ea68fb925"
      },
      "outputs": [],
      "source": [
        "model = Pretrainde_RESNET18()\n",
        "model.features.requires_grad_ = False\n",
        "model.to(DEVICE)\n",
        "\n",
        "main_loop = model_training(0.01, train_dataloader, valid_dataloader, DEVICE, model)\n",
        "main_loop.training_loop(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b78cffe-7e26-427a-ba1e-30824ff88b40",
      "metadata": {
        "id": "4b78cffe-7e26-427a-ba1e-30824ff88b40"
      },
      "outputs": [],
      "source": [
        "best_model = torch.load('./models/custom_transfer_model.pt')\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(y_predicts, y_labels):\n",
        "    acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
        "    return acc\n",
        "\n",
        "best_model.eval()\n",
        "running_loss_test = []\n",
        "running_acc_test = []\n",
        "\n",
        "for batch in tqdm(valid_dataloader):\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = best_model(inputs).to(DEVICE)\n",
        "    y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(DEVICE)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    running_loss_test.append(loss.item())\n",
        "    running_acc_test.append(accuracy(y_pred, labels))\n",
        "\n",
        "\n",
        "print(np.mean(running_loss_test))\n",
        "print(np.mean(running_acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AlexNet**"
      ],
      "metadata": {
        "id": "DejEv1D0chKJ"
      },
      "id": "DejEv1D0chKJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb98169b-4159-4052-8d10-0f79a3502e08",
      "metadata": {
        "id": "cb98169b-4159-4052-8d10-0f79a3502e08"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 200) -> None:\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, (11, 11), (4, 4), (2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((3, 3), (2, 2)),\n",
        "\n",
        "            nn.Conv2d(64, 192, (5, 5), (1, 1), (2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((3, 3), (2, 2)),\n",
        "\n",
        "            nn.Conv2d(192, 384, (3, 3), (1, 1), (1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, (3, 3), (1, 1), (1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, (3, 3), (1, 1), (1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((3, 3), (2, 2)),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028b0f0f-8d14-476d-8d3d-daace26d9ed7",
      "metadata": {
        "id": "028b0f0f-8d14-476d-8d3d-daace26d9ed7"
      },
      "outputs": [],
      "source": [
        "class model_training():\n",
        "\n",
        "    def __init__(self, lr, trainloader, testloader, device, model):\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.device = device\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.opt = optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr = lr,\n",
        "            weight_decay = 0.0001\n",
        "        )\n",
        "\n",
        "        self.best_model = None\n",
        "        self.best_epoch = None\n",
        "\n",
        "        self.loss_train = []\n",
        "        self.loss_test = []\n",
        "        self.metric_train = []\n",
        "        self.metric_test = []\n",
        "\n",
        "    def accuracy(self, y_predicts, y_labels):\n",
        "        acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
        "        return acc\n",
        "\n",
        "    def train_nn(self, trainloader, model, opt, loss_fn, device):\n",
        "\n",
        "        model.train()\n",
        "        running_loss_train = []\n",
        "        running_acc_train = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            outputs = model(inputs).to(device)\n",
        "            y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running_loss_train.append(loss.item())\n",
        "            running_acc_train.append(self.accuracy(y_pred, labels))\n",
        "\n",
        "        return model, running_loss_train, running_acc_train\n",
        "\n",
        "    def eval_nn(self, testloader, model, loss_fn, device):\n",
        "\n",
        "        model.eval()\n",
        "        running_loss_test = []\n",
        "        running_acc_test = []\n",
        "\n",
        "        for batch in tqdm(valid_dataloader):\n",
        "\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs).to(device)\n",
        "            y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            running_loss_test.append(loss.item())\n",
        "            running_acc_test.append(self.accuracy(y_pred, labels))\n",
        "\n",
        "        return running_loss_test, running_acc_test\n",
        "\n",
        "    def training_loop(self, max_epochs = 10):\n",
        "\n",
        "        print('Начинаю обучение')\n",
        "        start_training_time = time.time()\n",
        "\n",
        "        for epoch in tqdm(range(max_epochs)):\n",
        "\n",
        "            start_epoch_time = time.time()\n",
        "\n",
        "            self.model, running_loss_train, running_acc_train = self.train_nn(\n",
        "                self.trainloader,\n",
        "                self.model,\n",
        "                self.opt,\n",
        "                self.loss_fn,\n",
        "                self.device\n",
        "            )\n",
        "\n",
        "            running_loss_test, running_acc_test = self.eval_nn(\n",
        "                self.testloader,\n",
        "                self.model,\n",
        "                self.loss_fn,\n",
        "                self.device\n",
        "            )\n",
        "\n",
        "            self.loss_train.append(np.mean(running_loss_train))\n",
        "            self.loss_test.append(np.mean(running_loss_test))\n",
        "\n",
        "            self.metric_train.append(np.mean(running_acc_train))\n",
        "            self.metric_test.append(np.mean(running_acc_test))\n",
        "\n",
        "            if np.mean(running_acc_test) >= np.max(self.metric_test):\n",
        "                self.best_model = deepcopy(self.model)\n",
        "                self.best_epoch = epoch\n",
        "                torch.save(main_loop.best_model, './models/custom_model.pt')\n",
        "\n",
        "            duration_epoch = time.time() - start_epoch_time\n",
        "\n",
        "            print(f\"\"\"EPOCH {epoch} :\n",
        "            train_loss: {self.loss_train[-1]:.5f}\n",
        "            test_loss: {self.loss_test[-1]:.5f}\n",
        "            train_acc: {self.metric_train[-1]:.5f}\n",
        "            test_acc: {self.metric_test[-1]:.5f}\n",
        "            Эпоха заняла по времени {round(duration_epoch / 60, 2)} минут\"\"\")\n",
        "\n",
        "        duration_total = time.time() - start_training_time\n",
        "        print(f'Всего обучение заняло: {round(duration_total / 60, 2)} минут')\n",
        "        print(f'Лучшее значение метрики было достингнуто на {self.best_epoch} эпохе')\n",
        "\n",
        "        fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(10, 8))\n",
        "\n",
        "        axes[0, 0].plot(range(max_epochs), self.loss_train)\n",
        "        axes[0, 0].set_title('loss_train')\n",
        "\n",
        "        axes[0, 1].plot(range(max_epochs), self.loss_test)\n",
        "        axes[0, 1].set_title('loss_test')\n",
        "\n",
        "        axes[1, 0].plot(range(max_epochs), self.metric_train)\n",
        "        axes[1, 0].set_title('metric_train')\n",
        "\n",
        "        axes[1, 1].plot(range(max_epochs), self.metric_test)\n",
        "        axes[1, 1].set_title('metric_test')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad7070e3-5086-4732-9312-15bfad6d2a28",
      "metadata": {
        "id": "ad7070e3-5086-4732-9312-15bfad6d2a28"
      },
      "outputs": [],
      "source": [
        "model = AlexNet()\n",
        "model.to(DEVICE)\n",
        "\n",
        "main_loop = model_training(0.01, train_dataloader, valid_dataloader, DEVICE, model)\n",
        "main_loop.training_loop(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b925e08-9665-4493-9d27-ba62f595f461",
      "metadata": {
        "id": "9b925e08-9665-4493-9d27-ba62f595f461"
      },
      "outputs": [],
      "source": [
        "best_model = torch.load('./models/custom_model.pt')\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(y_predicts, y_labels):\n",
        "    acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
        "    return acc\n",
        "\n",
        "best_model.eval()\n",
        "running_loss_test = []\n",
        "running_acc_test = []\n",
        "\n",
        "for batch in tqdm(valid_dataloader):\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = best_model(inputs).to(DEVICE)\n",
        "    y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(DEVICE)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    running_loss_test.append(loss.item())\n",
        "    running_acc_test.append(accuracy(y_pred, labels))\n",
        "\n",
        "\n",
        "print(np.mean(running_loss_test))\n",
        "print(np.mean(running_acc_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}